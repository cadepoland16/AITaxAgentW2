# AITaxAgentW2

Local-first W-2 AI agent CLI built with Python, LangChain, Ollama, and Chroma.

## Install & Run (New Users)
### Prerequisites
- Python 3.11+
- Ollama installed (`https://ollama.com/download`)
- Local models:
```bash
ollama pull nomic-embed-text
ollama pull llama3.2
```

### Setup
```bash
git clone https://github.com/cadepoland16/AITaxAgentW2.git
cd AITaxAgentW2
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip install setuptools wheel
pip install -e .
```

### First Run
```bash
w2 ingest data/docs
w2 ask "What does Box 12 code DD represent?"
```

## Goals
- Keep sensitive tax data local by default
- Use retrieval-augmented generation (RAG) for grounded W-2 guidance
- Provide a practical CLI workflow for ingestion, Q&A, and validation

## Current Status
- Core CLI scaffold exists
- `ingest` implemented with LangChain + Chroma + Ollama embeddings
- `ask` implemented with retrieval + local LLM answer + source citations
- `validate` implemented with parsing + practical warning rules
- Repository standards and CI baseline added

## Tech Stack
- Python
- Typer CLI
- LangChain
- Ollama (local model runtime)
- Chroma (local vector store)

## Quickstart
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip install setuptools wheel
pip install -e .
w2 --help
```

## Build the RAG Index
Place source tax guidance files (`.txt`, `.md`, `.pdf`) in `data/docs/`, then run:

```bash
w2 ingest data/docs
```

Default output is persisted to `data/vectorstore/`.

## Ask Questions
```bash
w2 ask "Why might Box 1 be lower than Box 3?"
```
The response is generated by a local Ollama model and includes:
- Confidence signal from retrieval relevance
- Source citations with short snippets
- Insufficient-context handling when relevance is too low

Optional controls:
```bash
w2 ask "What does Box 12 code DD represent?" --top-k 5 --min-relevance 0.30
```

## Validate W-2 Files
```bash
w2 validate --w2-file "W2s(Confidential)/your-w2.pdf" --show-parsed
```
The command parses core fields and prints warning-style checks for review.
Extraction quality depends on PDF text readability.

Optional OCR fallback dependencies (for scanned/image-heavy PDFs):
```bash
pip install pdf2image pytesseract
```
You may also need native Tesseract installed on your OS.

## Run Tests
```bash
pytest -q
```
Includes unit tests for parsing/validation logic and CLI validation smoke tests.

## Demo (Step 9)
Quick demo:
```bash
./scripts/demo.sh
```

This demonstrates:
- Local ingestion
- Grounded Q&A with citations and confidence
- Insufficient-context behavior
- Validation on a synthetic W-2 sample

See `demo/README.md` for expected outputs.

## Troubleshooting
- `ConnectionError: Failed to connect to Ollama`:
  Start/restart Ollama (`ollama serve`) and verify with `ollama list`.
- `No matching distribution found` during install:
  Check Python version and network access, then retry inside activated `.venv`.
- `Insufficient context quality for a grounded answer`:
  Ingest more relevant docs or lower threshold, e.g. `--min-relevance 0.20`.
- Missing parsed W-2 fields:
  Install optional OCR deps (`pdf2image`, `pytesseract`) and ensure Tesseract is available.

## Security and Privacy
- W-2 files and PII must remain local and untracked
- `W2s(Confidential)/` is gitignored
- Review `SECURITY.md` before sharing logs or issue details

## Contributing
Please read:
- `CONTRIBUTING.md`
- `CODE_OF_CONDUCT.md`
- `SECURITY.md`

## License
MIT License. See [LICENSE](LICENSE).

## Disclaimer
This project is for informational and workflow-assist purposes only and does not provide legal, tax, or financial advice.
