# AITaxAgentW2

Local-first W-2 AI agent CLI built with Python, LangChain, Ollama, and Chroma.

## Goals
- Keep sensitive tax data local by default
- Use retrieval-augmented generation (RAG) for grounded W-2 guidance
- Provide a practical CLI workflow for ingestion, Q&A, and validation

## Current Status
- Core CLI scaffold exists
- `ingest` implemented with LangChain + Chroma + Ollama embeddings
- `ask` implemented with retrieval + local LLM answer + source citations
- `validate` is still a placeholder
- Repository standards and CI baseline added

## Tech Stack
- Python
- Typer CLI
- LangChain
- Ollama (local model runtime)
- Chroma (local vector store)

## Quickstart
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip install setuptools wheel
pip install -e .
w2 --help
```

## Build the RAG Index
Place source tax guidance files (`.txt`, `.md`, `.pdf`) in `data/docs/`, then run:

```bash
w2 ingest data/docs
```

Default output is persisted to `data/vectorstore/`.

## Ask Questions
```bash
w2 ask "Why might Box 1 be lower than Box 3?"
```
The response is generated by a local Ollama model and includes retrieved source citations.

## Security and Privacy
- W-2 files and PII must remain local and untracked
- `W2s(Confidential)/` is gitignored
- Review `SECURITY.md` before sharing logs or issue details

## Contributing
Please read:
- `CONTRIBUTING.md`
- `CODE_OF_CONDUCT.md`
- `SECURITY.md`

## License
MIT License. See [LICENSE](LICENSE).

## Disclaimer
This project is for informational and workflow-assist purposes only and does not provide legal, tax, or financial advice.
